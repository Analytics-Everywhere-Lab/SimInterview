{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "084691ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "_ = load_dotenv()\n",
    "api_key = os.environ[\"NVIDIA_API_KEY\"]\n",
    "\n",
    "\n",
    "def get_llm_output(temperature, max_tokens, system_role, prompt,\n",
    "                   frequency_penalty=0, presence_penalty=0, stop=None):\n",
    "    \"\"\"\n",
    "    G·ªçi LLM v√† tr·∫£ v·ªÅ n·ªôi dung response. N·∫øu system_role l√† chu·ªói r·ªóng,\n",
    "    ta ch·ªâ ƒë∆∞a message user, kh√¥ng ƒë∆∞a message system.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "        api_key=api_key,\n",
    "    )\n",
    "    # Ch·ªâ th√™m system message khi system_role kh√¥ng r·ªóng\n",
    "    messages = []\n",
    "    if system_role and system_role.strip():\n",
    "        messages.append({\"role\": \"system\", \"content\": system_role})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta/llama-3.3-70b-instruct\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        stop=stop,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print('Finish generating response in', round((end_time - start_time), 2), 'seconds')\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af73018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "\n",
    "def extract_text_from_pdfs(files):\n",
    "    \"\"\"Extract full text from a list of PDF files.\"\"\"\n",
    "    text = \"\"\n",
    "    for f in files or []:\n",
    "        with pymupdf.open(f) as pdf:\n",
    "            text += \"\".join(page.get_text() for page in pdf)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf01731",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdfs(['sample_resume.pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce4ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_cv(cv_text):\n",
    "    system_prompt = \"\"\"\n",
    "You are a professional resume/CV formatter. \n",
    "Reformat the candidate's resume text into a clean, modern structure with these sections:\n",
    "1. Header: Name, Contact Info\n",
    "2. Summary: 2‚Äì3 sentence career summary\n",
    "3. Experience: List of jobs with role, company, dates, bullet achievements\n",
    "4. Education: Degrees, institutions, years\n",
    "5. Projects (if any): title, description, technologies used\n",
    "6. Skills: grouped by category (e.g., Languages, Tools, Frameworks)\n",
    "7. Certifications (if any)\n",
    "\n",
    "Output the resume in Markdown format. Use consistent bullet points and headers.\n",
    "\"\"\"\n",
    "    # Chia nh·ªè n·∫øu CV qu√° d√†i (·ªü ƒë√¢y gi·∫£ ƒë·ªãnh cv_text < 4000 tokens)\n",
    "    prompt = f\"\"\"\n",
    "Raw Resume Text:\n",
    "\\\"\\\"\\\"\n",
    "{cv_text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Please reformat as described.\n",
    "\"\"\"\n",
    "    return get_llm_output(\n",
    "        temperature=0.3,\n",
    "        max_tokens=1500,\n",
    "        system_role=system_prompt,\n",
    "        prompt=prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a477c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish generating response in 7.64 seconds\n"
     ]
    }
   ],
   "source": [
    "aftext = structure_cv(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaaa533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Header\n",
      "FARAH MARTIN  \n",
      "Data Analyst  \n",
      "farahmartin@email.com | (123) 456-7890 | Brooklyn, NY | [LinkedIn](https://www.linkedin.com/in/farahmartin)\n",
      "\n",
      "### Summary\n",
      "Highly motivated and experienced data analyst with a strong background in mathematics and economics, leveraging technical skills to drive business growth and improvement. Proven track record of successfully implementing data-driven solutions to enhance operational efficiency, customer value, and revenue. Skilled in leading cross-functional teams and collaborating with executive teams to formulate and report on key performance indicators.\n",
      "\n",
      "### Experience\n",
      "* **Data Analyst, Fountain House**  \n",
      "  May 2018 - Current, New York, NY\n",
      "  * Built out the data and reporting infrastructure from the ground up using Tableau and SQL to provide real-time insights into the product, marketing funnels, and business KPIs.\n",
      "  * Designed and implemented A/B experiments for products to improve the conversion rate by 19 basis points and reduce churn by 12 basis points.\n",
      "  * Implemented long-term pricing experiment that improved customer value by 25%.\n",
      "  * Built operational reporting in Tableau to find areas of improvement for contractors resulting in $250K in annual incremental revenue.\n",
      "  * Led a team of 2 full-time employees and 4 contractors.\n",
      "* **Data Analyst, Wavely**  \n",
      "  August 2016 - May 2018, New York, NY\n",
      "  * Partnered directly with the executive team as the first data hire to formulate and report on KPIs across their web properties that received 225M visitors annually using SQL and Google Sheets.\n",
      "  * Built a logistic regression model to help the SEO team decide which keywords to target, resulting in a 15% lift in YoY site visitors in 2018.\n",
      "  * Collaborated with product managers to perform cohort analysis that identified an opportunity to reduce pricing by 22% for a segment of users to boost yearly revenue by $730K.\n",
      "  * Developed root cause reports to address problems with customer conversions, successfully revealing insights that boosted conversions by 32%.\n",
      "* **Product Modeling Analyst, Geico**  \n",
      "  August 2014 - August 2016, Washington D.C.\n",
      "  * Developed and owned reporting for a nationwide retention program with Python, SQL, and Excel, saving ~90 hours of monthly labor.\n",
      "  * Identified procedural areas of improvement through customer data, using SQL to help improve the profitability of a nationwide retention program by 8%.\n",
      "  * Applied models and data to understand and predict repair costs for vehicles on the market, and presented findings to stakeholders.\n",
      "\n",
      "### Education\n",
      "* **B.S. in Mathematics and Economics**, University of Pittsburgh, September 2010 - April 2014, Pittsburgh, PA\n",
      "\n",
      "### Skills\n",
      "* **Languages**: Python (Pandas, Scikit-learn), SQL\n",
      "* **Tools**: Excel, Google Sheets, Tableau, Google Analytics\n",
      "* **Frameworks**: A/B Testing & Experimentation\n",
      "* **Leadership**: Proven experience in leading teams and collaborating with executive teams\n",
      "\n",
      "### Certifications\n",
      "None listed.\n"
     ]
    }
   ],
   "source": [
    "print(aftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "640e170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_jd(jd_text):\n",
    "    system_prompt = \"\"\"\n",
    "You are a professional job description formatter. \n",
    "Reformat the candidate's job description text into a clean, modern structure with these sections. Leave 'no information' for any section that is not applicable:\n",
    "1. Header: Job Title, Company Name\n",
    "2. Summary: 2‚Äì3 sentence overview of the role\n",
    "3. Responsibilities: List of key responsibilities and tasks\n",
    "4. Requirements: Skills and qualifications needed\n",
    "5. Preferred Qualifications: Additional skills that are a plus\n",
    "6. Benefits: Perks and benefits offered\n",
    "7. Application Process: How to apply\n",
    "\n",
    "Output the job description in Markdown format. Use consistent bullet points and headers.\n",
    "\"\"\"\n",
    "    # Chia nh·ªè n·∫øu JD qu√° d√†i (·ªü ƒë√¢y gi·∫£ ƒë·ªãnh jd_text < 4000 tokens)\n",
    "    prompt = f\"\"\"\n",
    "Raw Job Description Text:\n",
    "\\\"\\\"\\\"\n",
    "{jd_text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Please reformat as described.\n",
    "\"\"\"\n",
    "    return get_llm_output(\n",
    "        temperature=0.3,\n",
    "        max_tokens=1200,\n",
    "        system_role=system_prompt,\n",
    "        prompt=prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d2ee7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish generating response in 5.58 seconds\n",
      "### Header: Data Analyst, [No Company Name]\n",
      "### Summary\n",
      "We are seeking a talented and detail-oriented Data Analyst to join our dynamic team, responsible for interpreting data, analyzing results, and providing actionable insights to drive informed decision-making. The Data Analyst will work closely with stakeholders to understand their data needs and present findings in a clear and concise manner. This role requires a strong analytical mindset and excellent communication skills.\n",
      "\n",
      "### Responsibilities\n",
      "* Extract, transform, and load (ETL) data from various sources\n",
      "* Clean and preprocess data to ensure accuracy and consistency\n",
      "* Develop scripts and workflows to automate data collection and processing tasks\n",
      "* Perform exploratory data analysis to uncover trends, patterns, and anomalies\n",
      "* Apply statistical and analytical techniques to derive insights from complex datasets\n",
      "* Conduct hypothesis testing and predictive modeling to support business objectives\n",
      "* Create visually appealing and interactive dashboards, reports, and presentations\n",
      "* Communicate findings and recommendations to stakeholders using data visualization tools\n",
      "* Validate data accuracy, completeness, and integrity\n",
      "* Identify and address data quality issues and discrepancies\n",
      "* Implement data quality controls and monitoring mechanisms\n",
      "* Partner with business units to define key performance indicators (KPIs) and metrics\n",
      "* Analyze business processes and operations to identify opportunities for improvement\n",
      "* Provide decision support through ad-hoc analysis and scenario modeling\n",
      "* Stay abreast of industry trends, best practices, and emerging technologies in data analytics\n",
      "* Participate in training programs and professional development opportunities\n",
      "* Share knowledge and insights with colleagues to foster a culture of continuous learning\n",
      "\n",
      "### Requirements\n",
      "* Bachelor's degree in Statistics, Mathematics, Computer Science, Economics, or related field (Master's degree preferred)\n",
      "* Proven experience in data analysis, business intelligence, or related roles\n",
      "* Proficiency in data analysis tools and programming languages (e.g., SQL, Python, R, etc.)\n",
      "* Strong analytical and problem-solving skills with attention to detail\n",
      "* Excellent communication and presentation abilities\n",
      "* Ability to work independently and collaboratively in a fast-paced environment\n",
      "\n",
      "### Preferred Qualifications\n",
      "* Experience with data visualization tools (e.g., Tableau, Power BI, etc.)\n",
      "* Knowledge of machine learning and data mining techniques\n",
      "\n",
      "### Benefits\n",
      "No information\n",
      "\n",
      "### Application Process\n",
      "No information\n"
     ]
    }
   ],
   "source": [
    "jd = extract_text_from_pdfs(['sample_jd.pdf'])\n",
    "afjdtext = structure_jd(jd)\n",
    "print(afjdtext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25dab01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feedback(cv_text, jd_text):\n",
    "    \"\"\"\n",
    "    Use LLM to generate structured, comprehensive feedback on the resume:\n",
    "    - ƒê∆∞a ra c√°c ti√™u ch√≠ ƒë√°nh gi√° (Assessment Criteria)\n",
    "    - ƒê√°nh gi√° t·ª´ng m·ª•c (Review) d·ª±a tr√™n ti√™u ch√≠\n",
    "    - G·ª£i √Ω c·∫£i ti·∫øn (Improvement Suggestions) ƒë·ªÉ tƒÉng t·ªâ l·ªá ƒë·∫≠u\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "You are a senior career advisor and HR specialist. \n",
    "Your task is to evaluate the candidate‚Äôs resume against the Job Description, \n",
    "using the following structured framework:\n",
    "\n",
    "1. Assessment Criteria:\n",
    "   a. Relevance of Experience ‚Äì How well past roles map to required responsibilities.\n",
    "   b. Skills Match ‚Äì Presence and prominence of key technical and soft skills.\n",
    "   c. Projects - Relevance and impact of projects related to the JD.\n",
    "   d. Achievement Impact ‚Äì Use of quantifiable results and action verbs.\n",
    "   e. Keywords & ATS Optimization ‚Äì Inclusion of terminology from the JD.\n",
    "   f. Clarity & Readability ‚Äì Logical sectioning, bullet usage, concise language.\n",
    "   g. Professional Branding ‚Äì Strong summary, consistent formatting, contact info.\n",
    "\n",
    "2. For each criterion:\n",
    "   - Provide a **brief review**: highlight strengths and gaps.\n",
    "   - Offer **2‚Äì3 short actionable suggestions** to improve that aspect of the resume.\n",
    "\n",
    "3. Finally, summarize **top 3 priority actions** the candidate should take \n",
    "   to significantly increase their chance of being shortlisted.\n",
    "\n",
    "Return your output in Markdown, with sections:\n",
    "## Assessment\n",
    "- **Relevance of Experience**  \n",
    "  - Review: ‚Ä¶  \n",
    "  - Suggestions:\n",
    "    1. ‚Ä¶\n",
    "    2. ‚Ä¶\n",
    "\n",
    "(Repeat for each criterion)\n",
    "\n",
    "## Top 3 Priority Actions\n",
    "1. ‚Ä¶\n",
    "2. ‚Ä¶\n",
    "3. ‚Ä¶\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Job Description:\n",
    "\\\"\\\"\\\"\n",
    "{jd_text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Candidate Resume:\n",
    "\\\"\\\"\\\"\n",
    "{cv_text}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "    return get_llm_output(\n",
    "        temperature=0.3,\n",
    "        max_tokens=1200,\n",
    "        system_role=system_prompt,\n",
    "        prompt=user_prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f35068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish generating response in 15.14 seconds\n"
     ]
    }
   ],
   "source": [
    "generated_feedback = generate_feedback(aftext, afjdtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f012b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Assessment\n",
      "### Relevance of Experience\n",
      "- Review: The candidate's experience is highly relevant to the job description, with a strong background in data analysis, business intelligence, and related roles. The candidate has worked in various industries, including insurance and non-profit, and has experience in leading cross-functional teams and collaborating with executive teams.\n",
      "- Suggestions:\n",
      "  1. Emphasize the specific skills and tools used in previous roles, such as SQL, Python, and Tableau, to match the job requirements.\n",
      "  2. Quantify the impact of previous projects, such as the 19 basis points improvement in conversion rate and 12 basis points reduction in churn, to demonstrate the value added to previous employers.\n",
      "  3. Consider adding a brief description of the company and industry for each previous role to provide context for the accomplishments.\n",
      "\n",
      "### Skills Match\n",
      "- Review: The candidate's skills match the job requirements, with proficiency in data analysis tools and programming languages, such as SQL, Python, and Tableau. However, the candidate could benefit from highlighting additional skills, such as machine learning and data mining techniques.\n",
      "- Suggestions:\n",
      "  1. Expand the skills section to include additional technical skills, such as R, Julia, or other programming languages relevant to the job.\n",
      "  2. Emphasize the candidate's experience with data visualization tools, such as Tableau, and highlight any certifications or training in these areas.\n",
      "  3. Consider adding a section for \"soft skills\" to highlight the candidate's excellent communication and presentation abilities.\n",
      "\n",
      "### Projects\n",
      "- Review: The candidate's projects and accomplishments are highly relevant to the job description, with a focus on data-driven solutions, operational efficiency, and revenue growth. However, the candidate could benefit from providing more details about the projects, such as the methodologies used and the impact on the business.\n",
      "- Suggestions:\n",
      "  1. Provide more details about the projects, such as the goals, methodologies, and outcomes, to demonstrate the candidate's expertise and value added.\n",
      "  2. Consider adding a separate section for \"projects\" or \"case studies\" to showcase the candidate's accomplishments and provide a clear overview of their experience.\n",
      "  3. Emphasize the candidate's ability to work independently and collaboratively on projects, and highlight any experience with agile methodologies or project management tools.\n",
      "\n",
      "### Achievement Impact\n",
      "- Review: The candidate's achievements are quantified, with specific metrics and outcomes, such as the 19 basis points improvement in conversion rate and 12 basis points reduction in churn. However, the candidate could benefit from using more action verbs and emphasizing the impact on the business.\n",
      "- Suggestions:\n",
      "  1. Use more action verbs, such as \"Improved,\" \"Increased,\" and \"Enhanced,\" to describe the candidate's achievements and emphasize the impact on the business.\n",
      "  2. Quantify the impact of the candidate's achievements, such as the revenue growth or cost savings, to demonstrate the value added to previous employers.\n",
      "  3. Consider adding a section for \"achievements\" or \"accomplishments\" to showcase the candidate's impact and provide a clear overview of their experience.\n",
      "\n",
      "### Keywords & ATS Optimization\n",
      "- Review: The candidate's resume includes relevant keywords, such as \"data analysis,\" \"business intelligence,\" and \"SQL,\" but could benefit from additional keywords and phrases to match the job requirements.\n",
      "- Suggestions:\n",
      "  1. Incorporate additional keywords and phrases from the job description, such as \"machine learning,\" \"data mining,\" and \"data visualization,\" to improve the candidate's visibility in applicant tracking systems (ATS).\n",
      "  2. Use a keyword cloud or tag cloud to visualize the candidate's skills and expertise, and provide a clear overview of their experience.\n",
      "  3. Consider adding a section for \"technical skills\" or \"tools\" to showcase the candidate's proficiency in specific software and programming languages.\n",
      "\n",
      "### Clarity & Readability\n",
      "- Review: The candidate's resume is well-organized, with clear section headings and concise bullet points. However, the candidate could benefit from using more white space and emphasizing the most important information.\n",
      "- Suggestions:\n",
      "  1. Use more white space to improve the readability of the resume, and emphasize the most important information, such as the candidate's achievements and skills.\n",
      "  2. Consider using a more modern font, such as Arial or Calibri, to improve the overall appearance of the resume.\n",
      "  3. Use bullet points and action verbs to describe the candidate's experience and achievements, and provide a clear overview of their skills and expertise.\n",
      "\n",
      "### Professional Branding\n",
      "- Review: The candidate's professional branding is strong, with a clear and concise summary, consistent formatting, and a professional online presence.\n",
      "- Suggestions:\n",
      "  1. Consider adding a professional summary or career objective statement to the top of the resume, to provide a clear overview of the candidate's experience and goals.\n",
      "  2. Use a consistent format throughout the resume, with clear section headings and concise bullet points, to improve the overall appearance and readability.\n",
      "  3. Emphasize the candidate's unique value proposition, such as their experience in leading cross-functional teams or collaborating with executive teams, to differentiate themselves from other candidates.\n",
      "\n",
      "## Top 3 Priority Actions\n",
      "1. **Emphasize relevant technical skills**: Incorporate additional keywords and phrases from the job description, such as \"machine learning,\" \"data mining,\" and \"data visualization,\" to improve the candidate's visibility in applicant tracking systems (ATS) and match the job requirements.\n",
      "2. **Quantify achievements and impact**: Use more action verbs and emphasize the impact on the business, such as the revenue growth or cost savings, to demonstrate the value added to previous employers and provide a clear overview of the candidate's experience.\n",
      "3. **Use a more modern and concise format**: Use more white space, a modern font, and concise bullet points to improve the readability and overall appearance\n"
     ]
    }
   ],
   "source": [
    "print(generated_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72afba",
   "metadata": {},
   "source": [
    "## Assessment\n",
    "### Relevance of Experience\n",
    "- Review: The candidate's experience is highly relevant to the job description, with a strong background in data analysis, business intelligence, and related roles. The candidate has worked in various industries, including insurance and non-profit, and has experience in leading cross-functional teams and collaborating with executive teams.\n",
    "- Suggestions:\n",
    "  1. Emphasize the specific skills and tools used in previous roles, such as SQL, Python, and Tableau, to match the job requirements.\n",
    "  2. Quantify the impact of previous projects, such as the 19 basis points improvement in conversion rate and 12 basis points reduction in churn, to demonstrate the value added to previous employers.\n",
    "  3. Consider adding a brief description of the company and industry for each previous role to provide context for the accomplishments.\n",
    "\n",
    "### Skills Match\n",
    "- Review: The candidate's skills match the job requirements, with proficiency in data analysis tools and programming languages, such as SQL, Python, and Tableau. However, the candidate could benefit from highlighting additional skills, such as machine learning and data mining techniques.\n",
    "- Suggestions:\n",
    "  1. Expand the skills section to include additional technical skills, such as R, Julia, or other programming languages relevant to the job.\n",
    "  2. Emphasize the candidate's experience with data visualization tools, such as Tableau, and highlight any certifications or training in these areas.\n",
    "  3. Consider adding a section for \"soft skills\" to highlight the candidate's excellent communication and presentation abilities.\n",
    "\n",
    "### Projects\n",
    "- Review: The candidate's projects and accomplishments are highly relevant to the job description, with a focus on data-driven solutions, operational efficiency, and revenue growth. However, the candidate could benefit from providing more details about the projects, such as the methodologies used and the impact on the business.\n",
    "- Suggestions:\n",
    "  1. Provide more details about the projects, such as the goals, methodologies, and outcomes, to demonstrate the candidate's expertise and value added.\n",
    "  2. Consider adding a separate section for \"projects\" or \"case studies\" to showcase the candidate's accomplishments and provide a clear overview of their experience.\n",
    "  3. Emphasize the candidate's ability to work independently and collaboratively on projects, and highlight any experience with agile methodologies or project management tools.\n",
    "\n",
    "### Achievement Impact\n",
    "- Review: The candidate's achievements are quantified, with specific metrics and outcomes, such as the 19 basis points improvement in conversion rate and 12 basis points reduction in churn. However, the candidate could benefit from using more action verbs and emphasizing the impact on the business.\n",
    "- Suggestions:\n",
    "  1. Use more action verbs, such as \"Improved,\" \"Increased,\" and \"Enhanced,\" to describe the candidate's achievements and emphasize the impact on the business.\n",
    "  2. Quantify the impact of the candidate's achievements, such as the revenue growth or cost savings, to demonstrate the value added to previous employers.\n",
    "  3. Consider adding a section for \"achievements\" or \"accomplishments\" to showcase the candidate's impact and provide a clear overview of their experience.\n",
    "\n",
    "### Keywords & ATS Optimization\n",
    "- Review: The candidate's resume includes relevant keywords, such as \"data analysis,\" \"business intelligence,\" and \"SQL,\" but could benefit from additional keywords and phrases to match the job requirements.\n",
    "- Suggestions:\n",
    "  1. Incorporate additional keywords and phrases from the job description, such as \"machine learning,\" \"data mining,\" and \"data visualization,\" to improve the candidate's visibility in applicant tracking systems (ATS).\n",
    "  2. Use a keyword cloud or tag cloud to visualize the candidate's skills and expertise, and provide a clear overview of their experience.\n",
    "  3. Consider adding a section for \"technical skills\" or \"tools\" to showcase the candidate's proficiency in specific software and programming languages.\n",
    "\n",
    "### Clarity & Readability\n",
    "- Review: The candidate's resume is well-organized, with clear section headings and concise bullet points. However, the candidate could benefit from using more white space and emphasizing the most important information.\n",
    "- Suggestions:\n",
    "  1. Use more white space to improve the readability of the resume, and emphasize the most important information, such as the candidate's achievements and skills.\n",
    "  2. Consider using a more modern font, such as Arial or Calibri, to improve the overall appearance of the resume.\n",
    "  3. Use bullet points and action verbs to describe the candidate's experience and achievements, and provide a clear overview of their skills and expertise.\n",
    "\n",
    "### Professional Branding\n",
    "- Review: The candidate's professional branding is strong, with a clear and concise summary, consistent formatting, and a professional online presence.\n",
    "- Suggestions:\n",
    "  1. Consider adding a professional summary or career objective statement to the top of the resume, to provide a clear overview of the candidate's experience and goals.\n",
    "  2. Use a consistent format throughout the resume, with clear section headings and concise bullet points, to improve the overall appearance and readability.\n",
    "  3. Emphasize the candidate's unique value proposition, such as their experience in leading cross-functional teams or collaborating with executive teams, to differentiate themselves from other candidates.\n",
    "\n",
    "## Top 3 Priority Actions\n",
    "1. **Emphasize relevant technical skills**: Incorporate additional keywords and phrases from the job description, such as \"machine learning,\" \"data mining,\" and \"data visualization,\" to improve the candidate's visibility in applicant tracking systems (ATS) and match the job requirements.\n",
    "2. **Quantify achievements and impact**: Use more action verbs and emphasize the impact on the business, such as the revenue growth or cost savings, to demonstrate the value added to previous employers and provide a clear overview of the candidate's experience.\n",
    "3. **Use a more modern and concise format**: Use more white space, a modern font, and concise bullet points to improve the readability and overall appearance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ed667",
   "metadata": {},
   "source": [
    "# Test RAG demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2293f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from src.variables import GPT_EMBEDDING_MODEL\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gradio as gr\n",
    "from langchain.schema import Document\n",
    "\n",
    "_ = load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69499cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"./chroma_db\"\n",
    "# Initialize embedding model and LLM\n",
    "embeddings = OpenAIEmbeddings(model=GPT_EMBEDDING_MODEL, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_rag_configs():\n",
    "    \"\"\"Initialize and return RAG configurations.\"\"\"\n",
    "    # Embedding model for RAG\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=GPT_EMBEDDING_MODEL,\n",
    "        openai_api_key=OPENAI_API_KEY\n",
    "    )\n",
    "    # Text splitter for chunking documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=150, \n",
    "                        length_function=len, separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "                    ) \n",
    "    return embeddings, text_splitter\n",
    "\n",
    "def save_doc_to_vector_store(text: str, collection_name: str, file_name: str = None):\n",
    "    \"\"\"Chunk text and index into Chroma under a specific collection.\"\"\"\n",
    "    embeddings, text_splitter = get_rag_configs()\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    metadatas = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        md = {\n",
    "            \"source\": collection_name,\n",
    "            \"chunk_id\": i,\n",
    "        }\n",
    "        if file_name is not None:\n",
    "            md[\"file_name\"] = file_name\n",
    "        metadatas.append(md)\n",
    "\n",
    "    docs = [\n",
    "        Document(page_content=chunks[i], metadata=metadatas[i])\n",
    "        for i in range(len(chunks))\n",
    "    ]\n",
    "    vectordb = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=PERSIST_DIR\n",
    "    )\n",
    "    # Add texts with metadata\n",
    "    vectordb.add_documents(documents=docs)\n",
    "    return vectordb\n",
    "\n",
    "vector_store = save_doc_to_vector_store(aftext, \"saveCV\", file_name=\"sample_resume.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f17077a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"Experience of the candidate in the field of DA and ML\",\n",
    "    k=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9220df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "\n",
      "**Content:**\n",
      "\n",
      "### Education\n",
      "* **B.S. in Mathematics and Economics**, University of Pittsburgh, September 2010 - April 2014, Pittsburgh, PA\n",
      "\n",
      "### Skills\n",
      "* **Languages**: Python (Pandas, Scikit-learn), SQL\n",
      "* **Tools**: Excel, Google Sheets, Tableau, Google Analytics\n",
      "* **Frameworks**: A/B Testing & Experimentation\n",
      "* **Leadership**: Proven experience in leading teams and collaborating with executive teams\n",
      "\n",
      "### Certifications\n",
      "None listed.\n",
      "\n",
      "**Metadata:**\n",
      "- **file_name**: sample_resume.pdf\n",
      "- **chunk_id**: 7\n",
      "- **source**: saveCV\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "**Content:**\n",
      "\n",
      "### Education\n",
      "* **B.S. in Mathematics and Economics**, University of Pittsburgh, September 2010 - April 2014, Pittsburgh, PA\n",
      "\n",
      "### Skills\n",
      "* **Languages**: Python (Pandas, Scikit-learn), SQL\n",
      "* **Tools**: Excel, Google Sheets, Tableau, Google Analytics\n",
      "* **Frameworks**: A/B Testing & Experimentation\n",
      "* **Leadership**: Proven experience in leading teams and collaborating with executive teams\n",
      "\n",
      "### Certifications\n",
      "None listed.\n",
      "\n",
      "**Metadata:**\n",
      "- **source**: saveCV\n",
      "- **chunk_id**: 7\n",
      "- **file_name**: sample_resume.pdf\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    # Markdown separator\n",
    "    print(\"---\\n\")\n",
    "    # Content section\n",
    "    print(f\"**Content:**\\n\\n{res.page_content}\\n\")\n",
    "    # Metadata section\n",
    "    print(\"**Metadata:**\")\n",
    "    for key, value in res.metadata.items():\n",
    "        print(f\"- **{key}**: {value}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed1c73",
   "metadata": {},
   "source": [
    "# Test gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbf065c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "_ = load_dotenv()\n",
    "api_key = os.environ[\"NVIDIA_API_KEY\"]\n",
    "\n",
    "\n",
    "def get_llm_output(temperature, max_tokens, system_role, prompt,\n",
    "                   frequency_penalty=0, presence_penalty=0, stop=None):\n",
    "    \"\"\"\n",
    "    G·ªçi LLM v√† tr·∫£ v·ªÅ n·ªôi dung response. N·∫øu system_role l√† chu·ªói r·ªóng,\n",
    "    ta ch·ªâ ƒë∆∞a message user, kh√¥ng ƒë∆∞a message system.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "        api_key=api_key,\n",
    "    )\n",
    "    # Ch·ªâ th√™m system message khi system_role kh√¥ng r·ªóng\n",
    "    messages = []\n",
    "    if system_role and system_role.strip():\n",
    "        messages.append({\"role\": \"system\", \"content\": system_role})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta/llama-3.3-70b-instruct\",\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        stop=stop,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print('Finish generating response in', round((end_time - start_time), 2), 'seconds')\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c176fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fixed system prompt for the interviewer persona\n",
    "INTERVIEWER_SYSTEM_PROMPT = \"\"\"\n",
    "You are a professional technical interviewer. \n",
    "Your goal is to ask clear, relevant follow-up questions to evaluate the candidate's skills and experience.\n",
    "Be concise, polite, and stay on topic.\n",
    "\"\"\"\n",
    "\n",
    "def interview(user_message, history):\n",
    "    \"\"\"\n",
    "    user_message: str, c√¢u v·ª´a n√≥i/v·ª´a tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n\n",
    "    history: list of (str, str) tuples, danh s√°ch c√°c l∆∞·ª£t (candidate, interviewer)\n",
    "    \n",
    "    Tr·∫£ v·ªÅ: (new_history, new_history) ƒë·ªÉ Gradio c·∫≠p nh·∫≠t Chatbot.\n",
    "    \"\"\"\n",
    "    # 1. Build a single prompt that includes past conversation\n",
    "    conversation = \"\"\n",
    "    for u, b in history:\n",
    "        conversation += f\"Candidate: {u}\\nInterviewer: {b}\\n\"\n",
    "    conversation += f\"Candidate: {user_message}\\nInterviewer:\"\n",
    "\n",
    "    # 2. Call your LLM wrapper\n",
    "    bot_reply = get_llm_output(\n",
    "        temperature=0.7,\n",
    "        max_tokens=500,\n",
    "        system_role=INTERVIEWER_SYSTEM_PROMPT,\n",
    "        prompt=conversation\n",
    "    )\n",
    "\n",
    "    # 3. Append to history\n",
    "    new_history = history + [(user_message, bot_reply)]\n",
    "\n",
    "    # Gradio Chatbot v·ªõi Textbox th∆∞·ªùng d√πng (history, history) l√†m outputs\n",
    "    return new_history, new_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e710899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from gtts import gTTS\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client for Whisper\n",
    "openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"speech to text.\"\"\"\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        resp = openai.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=f\n",
    "        )\n",
    "    return getattr(resp, \"text\", \"\") or getattr(resp, \"transcription\", \"\")\n",
    "\n",
    "def synthesize_speech(text, lang=\"en\"):\n",
    "    \"\"\"text to speech.\"\"\"\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    out_path = \"response.mp3\"\n",
    "    tts.save(out_path)\n",
    "    return out_path\n",
    "\n",
    "def voice_interaction(user_audio, history, q_idx):\n",
    "    # N·∫øu user ch∆∞a n√≥i g√¨\n",
    "    if not user_audio:\n",
    "        return history, None, history, q_idx\n",
    "\n",
    "    # STT\n",
    "    user_text = transcribe_audio(user_audio)\n",
    "    print(\"DEBUG: user_text =\", user_text)\n",
    "\n",
    "    # Next question\n",
    "    next_idx = q_idx + 1\n",
    "    if next_idx < len(INITIAL_QUESTIONS):\n",
    "        bot_text = INITIAL_QUESTIONS[next_idx]\n",
    "    else:\n",
    "        bot_text = \"üéâ Thank you! This concludes our interview.\"\n",
    "\n",
    "    # TTS cho c√¢u h·ªèi k·∫ø ti·∫øp\n",
    "    bot_audio = synthesize_speech(bot_text)\n",
    "\n",
    "    # Update history: add (user_answer, bot_question)\n",
    "    new_history = history + [(user_text, bot_text)]\n",
    "\n",
    "    return new_history, bot_audio, new_history, next_idx\n",
    "\n",
    "INITIAL_QUESTIONS = [\n",
    "    \"1. Tell me about a data analysis project where you used SQL to extract insights. What challenges did you face?\",\n",
    "    \"2. How have you used Python libraries like pandas or NumPy to clean and transform data?\",\n",
    "    \"3. Describe a dashboard you built in Tableau (or another BI tool). What metrics did you highlight?\",\n",
    "    # ‚Ä¶ add as many as you like\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb27b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20507/1812502522.py:11: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(value=initial, label=\"Interview Transcript\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: user_text = Ok, first I will mention which tool I use to query the data and convert it to seratable and then I use it to analyze the data and send it to the data modeling process to build the various predictors.\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(theme=gr.themes.Ocean()) as demo:\n",
    "    gr.Markdown(\"<h2 style='text-align: center;'>üé§ Voice Interview</h2>\")\n",
    "\n",
    "    # State: current question index (starts at 0)\n",
    "    question_idx = gr.State(0)\n",
    "    # State: chat history seeded with the first question\n",
    "    initial = [(\"\", INITIAL_QUESTIONS[0])]\n",
    "    chat_history = gr.State(initial)\n",
    "\n",
    "    # Chatbot UI showing transcript & questions\n",
    "    chatbot = gr.Chatbot(value=initial, label=\"Interview Transcript\")\n",
    "\n",
    "    with gr.Row():\n",
    "        \n",
    "        # Right column: voice controls\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"**Record your answer**\")\n",
    "            audio_in = gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"Record your answer\")\n",
    "            speak_btn = gr.Button(\"Send Voice\", variant=\"primary\", size=\"md\")\n",
    "            gr.Markdown(\"**Interviewer‚Äôs reply (audio)**\")\n",
    "            audio_out = gr.Audio(interactive=False, label=\"Response Audio\", autoplay=True)\n",
    "    demo.load(\n",
    "        fn=lambda: synthesize_speech(INITIAL_QUESTIONS[0]),\n",
    "        inputs=None,\n",
    "        outputs=audio_out\n",
    "    )\n",
    "    # Hook up button: process voice, update chat, play next question\n",
    "    speak_btn.click(\n",
    "        fn=voice_interaction,\n",
    "        inputs=[audio_in, chat_history, question_idx],\n",
    "        outputs=[chatbot, audio_out, chat_history, question_idx]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319198b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
